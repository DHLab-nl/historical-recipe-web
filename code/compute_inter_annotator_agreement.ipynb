{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# This notebook contains various metrics and methods to compute the inter annotator agreement \n",
    "# marieke.van.erp@dh.huc.knaw.nl\n",
    "# 2 April 2018\n",
    "\n",
    "df = {}\n",
    "df = pd.DataFrame(columns=['id','annotator','category','values'])\n",
    "for name in glob('../data/IngredientQuantitiesUnits_Annotations/Inter_Annotator_Agreement/*'):\n",
    "    name_elems = name.split(\"_\")\n",
    "    file2 = pd.read_csv(name)\n",
    "    for ind, row in file2.iterrows():\n",
    "        if row['TYPE'] == \"PERSON\":\n",
    "            row2 = [name_elems[3][:-4], name_elems[2], 'INGREDIENTS', row[\"QUOTE_TRANSCRIPTION\"].lower() ] \n",
    "            df.loc[len(df) ] = row2\n",
    "            row2 = []\n",
    "        if row['TYPE'] == \"PLACE\":\n",
    "            row3 = [name_elems[3][:-4], name_elems[2], 'QUANTITIES', row[\"QUOTE_TRANSCRIPTION\"].lower() ] \n",
    "            df.loc[len(df) ] = row3\n",
    "            row3 = []\n",
    "        if row['TYPE'] == \"EVENT\":\n",
    "            row4 = [name_elems[3][:-4], name_elems[2], 'OCR', row[\"QUOTE_TRANSCRIPTION\"].lower() ] \n",
    "            df.loc[len(df)  ] = row4\n",
    "            row4 = [] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what's in the dataframe \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here's a little hack to be able to discern which values came from which file in the end\n",
    "# We're adding a column in which each annotated item is prefixed by the file id from the \n",
    "# file in which the annotation was made \n",
    "df['newvalues'] = df['id'] + \"_\" + df['values'].astype(str)\n",
    "# Check what the dataframe contains now \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we store the annotations per annotator and per category in one cell \n",
    "df[\"annotation_bins\"] = df[\"annotator\"].astype(str) + \"_\" + df['category'].astype(str)\n",
    "huppeldepupje = pd.DataFrame(columns=['annotation_bins', 'ingr_set'])\n",
    "huppeldepupje = df.groupby(['annotation_bins'])['newvalues'].apply(set)\n",
    "# Some fixing to convert this to a dataframe and to reset the column names \n",
    "newframe = huppeldepupje.to_frame()\n",
    "newnewframe = newframe.reset_index(level='annotation_bins')\n",
    "# Check what's up\n",
    "newnewframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now store the annotations from the dataframe in a dictionary \n",
    "annotations = {} \n",
    "for hip, hop in newnewframe.iterrows():\n",
    "    annotations[hop['annotation_bins']] = hop['newvalues'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krippendorff's alpha via NLTK \n",
    "from nltk.metrics.agreement import AnnotationTask\n",
    "from nltk.metrics import interval_distance, binary_distance\n",
    "\n",
    "\n",
    "iaa_data = []\n",
    "for x in annotations:\n",
    "    if \"a1\" in x or \"a2\" in x or \"a3\" in x:\n",
    "        ann_cat = x.split(\"_\")[1]\n",
    "        ann_cat = ann_cat.replace(\"INGREDIENTS\", \"1\")\n",
    "        ann_cat = ann_cat.replace(\"QUANTITIES\", \"2\")\n",
    "        ann_cat = ann_cat.replace(\"OCR\", \"3\")\n",
    "        annotator = x.split(\"_\")[0]\n",
    "        for y in annotations[x]:\n",
    "            ann_tuple = (annotator, y, int(ann_cat))\n",
    "            iaa_data.append(ann_tuple)\n",
    "        \n",
    "t = AnnotationTask(iaa_data, distance=binary_distance)\n",
    "result = t.alpha()\n",
    "print(\"binary: \",result)\n",
    "\n",
    "t = AnnotationTask(iaa_data, distance=interval_distance)\n",
    "result = t.alpha()\n",
    "print(\"interval: \",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a bit of extra stuff to check where the annotators didn't agree with each other \n",
    "# Compute precision, recall and F-measure from sets \n",
    "def prec_r_f(a1,a2):\n",
    "    tp = a1.intersection(a2)\n",
    "    fp = a2.difference(a1)\n",
    "    fn = a1.difference(a2)\n",
    "    precision = len(tp) / (len(tp) + len(fp))\n",
    "    recall = len(tp) / (len(tp) + len(fn)) \n",
    "    f = (precision + recall) / 2 \n",
    "    unweighed_agreement = len(tp) / (len(a1) + len(a2) / 2 )\n",
    "    answer = \"items agreement\\t\" + str(len(tp)) + \"\\tunweighted agreement\\t\" + str(unweighed_agreement) +\"\\tItemsA1:\\t\" + str(len(a1)) + \"\\tItemsA2:\\t\" + str(len(a2)) + \"\\tp:\\t\" + str(precision) + \"\\tr:\\t\" + str(recall) + \"\\tf1:\\t\" + str(f) + \"\\nin A2 not in A1\" + str(fp) + \"\\nin A1 not in A2\" + str(fn) \n",
    "    return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, Recall & F_Measure \n",
    "# Also: output of where the annotators didn't agree \n",
    "\n",
    "list_of_pairs = []\n",
    "for x in annotations:\n",
    "    elems = x.split(\"_\")\n",
    "    tuple1 = ( \"a2_\" + elems[1], \"a1_\" + elems[1])\n",
    "    tuple2 = ( \"a3_\" + elems[1],  \"a1_\"+ elems[1])\n",
    "    tuple3 = ( \"a2_\"+ elems[1], \"a3_\"+ elems[1])\n",
    "    list_of_pairs.append(tuple1)\n",
    "    list_of_pairs.append(tuple2)\n",
    "    list_of_pairs.append(tuple3)\n",
    "\n",
    "unique = set(list_of_pairs)\n",
    "unique = list(unique)\n",
    "\n",
    "    \n",
    "\n",
    "for item in unique:\n",
    "    try:\n",
    "        prf = prec_r_f(annotations[item[0]], annotations[item[1]])\n",
    "        print(item[0] + \"\\t\" + item[1] + \"\\t\" + prf)\n",
    "    except:\n",
    "        pass\n",
    "        print(item[0] + \"\\t\" + item[1], \"p:\\t0\\tr:\\t0\\tf1:\\t0\")\n",
    "    \n",
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
